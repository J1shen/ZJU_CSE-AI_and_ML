{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "# 忽视警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_py.Utils import plot_image\n",
    "from torch_py.MTCNN.detector import FaceDetector\n",
    "from torch_py.MobileNetV1 import MobileNetV1\n",
    "from torch_py.FaceRec import Recognition\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# -------------------------- 请加载您最满意的模型 ---------------------------\n",
    "# 加载模型(请加载你认为的最佳模型)\n",
    "# 加载模型,加载请注意 model_path 是相对路径, 与当前文件同级。\n",
    "# 如果你的模型是在 results 文件夹下的 dnn.h5 模型，则 model_path = 'results/temp.pth'\n",
    "model_path = None\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def predict(img):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param img: cv2.imread 图像\n",
    "    :return: 预测的图片中的总人数、其中佩戴口罩的人数\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    # 将 cv2.imread 图像转化为 PIL.Image 图像，用来兼容测试输入的 cv2 读取的图像（勿删！！！）\n",
    "    # cv2.imread 读取图像的类型是 numpy.ndarray\n",
    "    # PIL.Image.open 读取图像的类型是 PIL.JpegImagePlugin.JpegImageFile\n",
    "    if isinstance(img, np.ndarray):\n",
    "        # 转化为 PIL.JpegImagePlugin.JpegImageFile 类型\n",
    "        img = Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "    detector = FaceDetector()\n",
    "    recognize = Recognition(model_path='test.pth')\n",
    "    recognize.mobilenet.eval()\n",
    "    draw, all_num, mask_num = recognize.mask_recognize(img)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    return all_num,mask_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(cv2.imread('test.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('temp2.pth', map_location=\"cpu\")\n",
    "torch.save(state_dict, 'test2.pth', _use_new_zipfile_serialization=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "837d281b97c32b6fba8a22a51e8bf9f92d63e55ecdb04e291285888e30439b4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
